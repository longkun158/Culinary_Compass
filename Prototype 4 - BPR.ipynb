{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf3102f-6ff2-440d-8e0d-583d567c2e11",
   "metadata": {},
   "source": [
    "## Loading Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207ebb55-7e60-4694-9ebb-589bd618be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load Data\n",
    "flavor_embedded_path = \"flavor_embedded.pkl\"\n",
    "menu_embedded_path = \"menu_embedded.pkl\"\n",
    "user_dataset_path = \"user_dataset.csv\"\n",
    "\n",
    "with open(flavor_embedded_path, \"rb\") as f:\n",
    "    flavor_embedded = pickle.load(f)\n",
    "\n",
    "with open(menu_embedded_path, \"rb\") as f:\n",
    "    menu_embedded = pickle.load(f)\n",
    "\n",
    "# Defining the column\n",
    "embedding_col = \"Embeddings\"\n",
    "\n",
    "# Convert \"Element\" column to lowercase for consistent matching\n",
    "flavor_embedded[\"Element\"] = flavor_embedded[\"Element\"].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0e1cc-caea-4bdb-972a-c4ac96a2a41b",
   "metadata": {},
   "source": [
    "## (Main 1) Applying IPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d0c21d7-4ab7-4ee6-a755-f0f9e1942d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply IPCA and ensure 1 × 300D output\n",
    "def aggregate_embeddings_ipca(embedding_list):\n",
    "    \"\"\"\n",
    "    Aggregates multiple ingredient embeddings into a single vector using IPCA.\n",
    "    Ensures output is always 1 × 300D.\n",
    "    \"\"\"\n",
    "    if isinstance(embedding_list, list) and len(embedding_list) > 0:\n",
    "        embedding_array = np.array(embedding_list)\n",
    "        \n",
    "        # Ensure embeddings are 2D and contain valid data\n",
    "        if embedding_array.ndim == 2 and embedding_array.shape[0] > 1:\n",
    "            ipca = IncrementalPCA(n_components=1, batch_size=min(embedding_array.shape[0], 50))\n",
    "            ipca_embedding = ipca.fit_transform(embedding_array.T).flatten()  # Ensure 1 × 300D\n",
    "            \n",
    "            # Fix cases where IPCA might return fewer than 300D\n",
    "            if len(ipca_embedding) < 300:\n",
    "                ipca_embedding = np.pad(ipca_embedding, (0, 300 - len(ipca_embedding)), mode='constant')\n",
    "            \n",
    "            return ipca_embedding\n",
    "        elif embedding_array.ndim == 2 and embedding_array.shape[0] == 1:\n",
    "            return embedding_array.flatten()  # Use single embedding if only one available\n",
    "    \n",
    "    return np.zeros(300)  # Default zero vector for empty cases\n",
    "\n",
    "# Apply the fixed IPCA aggregation to both datasets\n",
    "menu_embedded[\"Aggregated_Embeddings\"] = menu_embedded[embedding_col].apply(aggregate_embeddings_ipca)\n",
    "flavor_embedded[\"Aggregated_Embeddings\"] = flavor_embedded[embedding_col].apply(aggregate_embeddings_ipca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3cfad-2583-41ca-8413-424efd932680",
   "metadata": {},
   "source": [
    "## Loading User Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea6b01c-ef87-46fc-85e2-79b7611d5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "user_dataset = pd.read_csv(user_dataset_path)\n",
    "\n",
    "\n",
    "def safe_convert_embedding(x):\n",
    "    if isinstance(x, str):  # Check if the input is a string (stored as text in CSV)\n",
    "        try:\n",
    "            # Ensure commas exist before evaluating\n",
    "            formatted_x = x.replace(\" \", \",\") if \" \" in x and \",\" not in x else x\n",
    "            return np.array(ast.literal_eval(formatted_x))\n",
    "        except (SyntaxError, ValueError):  # Handle cases where parsing fails\n",
    "            print(f\"Error parsing embedding: {x}\")\n",
    "            return np.zeros(300)  # Default to zero vector if parsing fails\n",
    "    return x  # If already a NumPy array, return as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a1b89-0928-45f3-8f43-707bf9490e1c",
   "metadata": {},
   "source": [
    "## (Main 2) Using Cosine Similarity to match dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a1558b-6b65-49a1-814b-680ad2025f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Matching Menus Using Cosine Similarity\n",
    "def retrieve_matching_menus(flavor_inputs, user_id=None, top_n=5):\n",
    "    \"\"\"\n",
    "    Finds the top N menu items that best match the given flavor inputs.\n",
    "    Adjusts ranking based on user preferences if user_id is provided.\n",
    "    \"\"\"\n",
    "    # Convert input flavors to lowercase\n",
    "    flavor_inputs = [flavor.lower().strip() for flavor in flavor_inputs]\n",
    "    \n",
    "    # Retrieve the corresponding aggregated embeddings for all flavor inputs\n",
    "    flavor_rows = flavor_embedded[flavor_embedded[\"Element\"].isin(flavor_inputs)]\n",
    "    if flavor_rows.empty:\n",
    "        return pd.DataFrame({\"Error\": [f\"No matching flavors found for {flavor_inputs}.\"]})\n",
    "\n",
    "    # Compute mean of all selected flavor embeddings to form a single input vector\n",
    "    flavor_vectors = np.stack(flavor_rows[\"Aggregated_Embeddings\"].values)\n",
    "    combined_flavor_vector = np.mean(flavor_vectors, axis=0).reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity with all menu items\n",
    "    menu_vectors = np.stack(menu_embedded[\"Aggregated_Embeddings\"].dropna().values)  # Stack menu embeddings\n",
    "    similarities = cosine_similarity(combined_flavor_vector, menu_vectors)[0]\n",
    "\n",
    "    # Adjust ranking based on user preferences\n",
    "    if user_id is not None:\n",
    "        user_embedding = get_user_embedding(user_id)\n",
    "        similarities += cosine_similarity(user_embedding.reshape(1, -1), menu_vectors)[0] * 0.1  # Small weight adjustment\n",
    "\n",
    "    # Get top menu matches\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]  # Get top indices sorted by similarity\n",
    "    top_menus = menu_embedded.iloc[top_indices][[\"menu_item\", \"description\", \"ingredients_mapped\", \"dish_id\"]]\n",
    "    top_menus[\"Similarity\"] = similarities[top_indices]\n",
    "\n",
    "    return top_menus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6572770-1b1f-4f4d-9e5c-60eb94b66367",
   "metadata": {},
   "source": [
    "## (Main 3) Learn/ Update User Interaction Using BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843c2681-14f9-4622-b0d5-217c7efe2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user embedding (default to neutral if new user)\n",
    "def get_user_embedding(user_id):\n",
    "    if user_id in user_dataset[\"user_id\"].values:  # Just reading user_dataset\n",
    "        return np.array(user_dataset.loc[user_dataset[\"user_id\"] == user_id, \"user_embedding\"].values[0])\n",
    "    \n",
    "    return np.zeros(300)  # Default to neutral vector\n",
    "\n",
    "# Update User Preferences Using BPR\n",
    "def update_user_preference(user_id, dish_id, feedback):\n",
    "    \"\"\"\n",
    "    This function remember or add new user to learn weight for each interaction\n",
    "    \"\"\"\n",
    "    global user_dataset\n",
    "\n",
    "    # Check if user exists in dataset\n",
    "    if user_id not in user_dataset[\"user_id\"].values:\n",
    "        user_vector = np.zeros(300)\n",
    "        new_user = pd.DataFrame([[user_id, user_vector.tolist(), [], []]], \n",
    "                                columns=[\"user_id\", \"user_embedding\", \"liked_dishes\", \"disliked_dishes\"])\n",
    "        user_dataset = pd.concat([user_dataset, new_user], ignore_index=True)\n",
    "\n",
    "    # Retrieve user embedding and update it dynamically\n",
    "    user_idx = user_dataset[user_dataset[\"user_id\"] == user_id].index[0]\n",
    "    user_embedding = np.array(user_dataset.at[user_idx, \"user_embedding\"])\n",
    "    \n",
    "    # Get dish embedding\n",
    "    dish_embedding = menu_embedded.loc[menu_embedded[\"dish_id\"] == dish_id, \"Aggregated_Embeddings\"]\n",
    "    \n",
    "    if dish_embedding.empty:\n",
    "        print(f\"Dish ID {dish_id} not found in dataset.\")\n",
    "        return\n",
    "    \n",
    "    dish_embedding = np.array(dish_embedding.values[0])\n",
    "\n",
    "    # Bayesian Personalized Ranking (BPR) update\n",
    "    if feedback == \"positive\":\n",
    "        user_embedding += 0.05 * (dish_embedding - user_embedding)  # Move user vector closer to liked dish\n",
    "        user_dataset.at[user_idx, \"liked_dishes\"] = user_dataset.at[user_idx, \"liked_dishes\"] + [dish_id]\n",
    "    else:\n",
    "        user_embedding -= 0.05 * (dish_embedding - user_embedding)  # Move user vector away from disliked dish\n",
    "        user_dataset.at[user_idx, \"disliked_dishes\"] = user_dataset.at[user_idx, \"disliked_dishes\"] + [dish_id]\n",
    "    \n",
    "    # Save updated user embedding\n",
    "    user_dataset.at[user_idx, \"user_embedding\"] = user_embedding.tolist()\n",
    "    \n",
    "    # Save back to CSV\n",
    "    user_dataset.to_csv(user_dataset_path, index=False)\n",
    "    print(f\"User {user_id} preference updated based on {feedback} feedback for Dish {dish_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9a031-838d-4ed0-a9d4-665d93d9db6a",
   "metadata": {},
   "source": [
    "## Running the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0d287c-3085-4ca2-9a82-11a096db16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your User ID:  1\n",
      "Enter a flavor (e.g., 'sweet', 'sour'):  sour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Dishes:\n",
      "                 menu_item                                        description  \\\n",
      "26          Makdous Fatteh  Ground beef yogurt tahini pomegranate molasses...   \n",
      "290  Shashlik Paneer Tikka  Soft and creamy cubes of cottage cheese marina...   \n",
      "291  Gilafi Chicken Kebabs  Minced Chicken marinated with rosemary and cho...   \n",
      "479      Chana Chaat Papri  A street food classic, made with chickpeas cra...   \n",
      "292     Pepper Corn Prawns  Tiger prawns, marinated with lemon yogurt and ...   \n",
      "\n",
      "                                    ingredients_mapped  dish_id  Similarity  \n",
      "26   ground_beef, yogurt, tahini, pomegranate_molas...       27    0.721379  \n",
      "290  panir, bell_pepper, pineapple, onion, yogurt, ...      291    0.710954  \n",
      "291  minced_chicken, rosemary, bell_pepper, yogurt,...      292    0.698447  \n",
      "479  chickpea, paprika, frozen_vegetable, yogurt, t...      480    0.694142  \n",
      "292  king_prawn, lemon_juice, yogurt, garlic, ginge...      293    0.682456  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Dish_ID of the dish you want to pick:  26\n",
      "Did you like the dish? (positive/negative):  positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 preference updated based on positive feedback for Dish 26.\n"
     ]
    }
   ],
   "source": [
    "# --- Simulating the System ---\n",
    "def interactive_session():\n",
    "    user_id = input(\"Enter your User ID: \")\n",
    "    \n",
    "    flavor_choice = input(\"Enter a flavor (e.g., 'sweet', 'sour'): \").strip().lower()\n",
    "    recommended_dishes = retrieve_matching_menus([flavor_choice], user_id=user_id)\n",
    "    \n",
    "    if recommended_dishes.empty:\n",
    "        print(\"No recommendations found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nRecommended Dishes:\")\n",
    "    print(recommended_dishes)\n",
    "\n",
    "    selected_dish_id = int(input(\"Enter the Dish_ID of the dish you want to pick: \"))\n",
    "    feedback = input(\"Did you like the dish? (positive/negative): \").strip().lower()\n",
    "\n",
    "    if feedback in [\"positive\", \"negative\"]:\n",
    "        update_user_preference(user_id, selected_dish_id, feedback)\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 'positive' or 'negative'.\")\n",
    "\n",
    "# Run interactive system\n",
    "interactive_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce958e-a9d8-4467-b5ce-795ed65d1525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
